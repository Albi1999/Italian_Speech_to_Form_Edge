{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6owcHtPSmRKh",
        "outputId": "27107940-28da-41ed-dce9-3bc6bf7b918a"
      },
      "outputs": [],
      "source": [
        "!pip install TTS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfwZ92iUK-3Z",
        "outputId": "214568b9-06ab-4ca3-eeab-637c1de7f384"
      },
      "outputs": [],
      "source": [
        "!pip install numpy==1.26.4 --force-reinstall\n",
        "# Dopo aver eseguito questa cella riavviare il runtime !!!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "G4aCQFNVK-MV",
        "outputId": "17246c8a-858f-4675-e99a-c6332b1b1a63"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import json\n",
        "from TTS.api import TTS\n",
        "from tqdm import tqdm\n",
        "from google.colab import files\n",
        "import random\n",
        "\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QRmPoRlakSnc",
        "outputId": "3472f7bc-3fb6-460a-ed45-ad8e38050b73"
      },
      "outputs": [],
      "source": [
        "sentences_filename = \"sentences.json\"\n",
        "\n",
        "if sentences_filename not in uploaded:\n",
        "    print(f\"Errore: Il file '{sentences_filename}' non è stato caricato.\")\n",
        "else:\n",
        "    print(f\"Caricamento di '{sentences_filename}' completato.\")\n",
        "    with open(sentences_filename, \"r\", encoding=\"utf-8\") as f:\n",
        "        # Ora all_sentences è una LISTA DI STRINGHE\n",
        "        all_sentences = json.load(f)\n",
        "        print(f\"Caricate {len(all_sentences)} frasi.\")\n",
        "\n",
        "    half = len(all_sentences) // 2\n",
        "    sentences_split = {\n",
        "        \"tts_models/it/mai_female/glow-tts\": {\n",
        "            \"sentences\": all_sentences[:half], # Prima metà delle frasi (lista di stringhe)\n",
        "            \"gender\": \"female\"\n",
        "        },\n",
        "        \"tts_models/it/mai_male/glow-tts\": {\n",
        "            \"sentences\": all_sentences[half:], # Seconda metà delle frasi (lista di stringhe)\n",
        "            \"gender\": \"male\"\n",
        "        }\n",
        "    }\n",
        "\n",
        "    base_output_dir = \"coqui_output\"\n",
        "    os.makedirs(base_output_dir, exist_ok=True)\n",
        "\n",
        "    all_final_samples_metadata = []\n",
        "\n",
        "    for model_name, data in sentences_split.items():\n",
        "        sentences_list = data[\"sentences\"]\n",
        "        gender = data[\"gender\"]\n",
        "        subfolder = os.path.join(base_output_dir, gender)\n",
        "        os.makedirs(subfolder, exist_ok=True)\n",
        "\n",
        "        print(f\"\\nInizializzazione modello Coqui TTS: {model_name}...\")\n",
        "        try:\n",
        "             tts = TTS(model_name=model_name, progress_bar=True)\n",
        "             print(f\"Modello {model_name} caricato.\")\n",
        "        except Exception as e:\n",
        "             print(f\"Errore durante il caricamento del modello {model_name}: {e}\")\n",
        "             continue\n",
        "\n",
        "        current_split_metadata = []\n",
        "\n",
        "        print(f\"Generazione audio per {len(sentences_list)} frasi ({gender})...\")\n",
        "        for i, sentence_text in tqdm(enumerate(sentences_list), total=len(sentences_list), desc=f\"Processing {gender}\"):\n",
        "            text = sentence_text\n",
        "            global_index = i if gender == \"female\" else i + half\n",
        "\n",
        "            output_filename = f\"sample_{global_index}_{gender}.wav\"\n",
        "            output_path = os.path.join(subfolder, output_filename)\n",
        "\n",
        "            try:\n",
        "                tts.tts_to_file(text=text, file_path=output_path)\n",
        "\n",
        "                sample_metadata = {\n",
        "                    \"id\": global_index,\n",
        "                    \"text\": text,\n",
        "                    \"coqui_audio_path\": os.path.join(gender, output_filename),\n",
        "                    \"coqui_model\": model_name,\n",
        "                    \"speaker_gender\": gender\n",
        "                }\n",
        "                current_split_metadata.append(sample_metadata)\n",
        "\n",
        "            except Exception as e_tts:\n",
        "                print(f\"\\nErrore durante la sintesi per la frase {global_index} ({gender}): {e_tts}\")\n",
        "\n",
        "        metadata_split_path = os.path.join(subfolder, \"samples_coqui.json\")\n",
        "        try:\n",
        "            with open(metadata_split_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                json.dump(current_split_metadata, f, indent=2, ensure_ascii=False)\n",
        "            print(f\"Metadati per '{gender}' salvati in: {metadata_split_path}\")\n",
        "            all_final_samples_metadata.extend(current_split_metadata)\n",
        "        except Exception as e_save:\n",
        "            print(f\"Errore durante il salvataggio dei metadati per '{gender}': {e_save}\")\n",
        "\n",
        "\n",
        "    global_metadata_path = os.path.join(base_output_dir, \"all_samples_coqui.json\")\n",
        "    try:\n",
        "        all_final_samples_metadata.sort(key=lambda x: x['id'])\n",
        "        with open(global_metadata_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(all_final_samples_metadata, f, indent=2, ensure_ascii=False)\n",
        "        print(f\"\\nMetadati globali aggregati salvati in: {global_metadata_path}\")\n",
        "    except Exception as e_save_global:\n",
        "         print(f\"Errore durante il salvataggio dei metadati globali: {e_save_global}\")\n",
        "\n",
        "\n",
        "    print(\"\\nCreazione file zip...\")\n",
        "    zip_filename = \"coqui_output.zip\"\n",
        "    !zip -r {zip_filename} {base_output_dir}\n",
        "    print(f\"File '{zip_filename}' creato. Avvio download...\")\n",
        "    files.download(zip_filename)\n",
        "    print(\"Download completato.\")\n",
        "\n",
        "if sentences_filename not in uploaded:\n",
        "     print(\"\\nOperazione interrotta perché il file sentences.json non è stato caricato.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
